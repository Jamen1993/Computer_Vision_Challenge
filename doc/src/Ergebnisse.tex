\section{Ergebnisse}
Die Ergebnisse für die geforderten Skalierungsfaktoren können im Ordner \textit{doc/virtual\_views} eingesehen werden. Die Benennung zeigt vorne den Faktor für die Skalierung der Transformation und hinten das Bildpaar. Wir haben die Bilder nicht direkt in die Dokumentation eingefügt, damit sie in voller Auflösung zur Verfügung stehen und beliebig angesehen werden können.

Die von uns übernommenen und selbst programmierten Funktionen finden sich im Ordner \textit{lib}. Im Ordner \textit{src} ist das Skript \textit{challenge} entsprechend Aufgabenstellung der Einstiegspunkt für die Ausführung. Im Unterordner \textit{GUI} gibt es noch ein Skript namens \textit{challenge}, aber diesmal wird die GUI gestartet. Für die Anwendung der GUI müssen Bilder und Kalibrierungsmatrix geladen werden. Bilder können im Ordner \textit{images}, Kalibrierungsmatrizen im Ordner \textit{data} gefunden werden. \textit{K1} ist die Kalibrierungsmatrix für die Bilder \textit{L1} und \textit{R1} und \textit{K2} ist die Kalibrierungsmatrix für die Bilder \textit{L2} und \textit{R2}.

\subsection{Laufzeit Benchmark}
Zur Evaluierung der Ausführungsdauer unseres Algorithmus haben wir verschiedene virtuelle Ansichten auf unterschiedlichen Systemen berechnet und dabei die Laufzeiten gestoppt. Um zuverlässigere Ergebnisse zu bekommen, haben wir die selbe Berechnung mehrmals ausgeführt und anschließend den Mittelwert und die Standardabweichung der Laufzeit berechnet. So haben wir die virtuellen Ansichten für $p \in [0.2, 0.45, 0.7, 1]$ jeweils 5 mal für beide Bildpaare berechnet, um schließlich die Laufzeiten von insgesamt 40 Durchläufen der Funktion $free\_viewpoint$ zu erhalten. Dabei ergaben sich die in Tabelle \ref{tab:evaluierung_laufzeiten} dargestellten Ergebnisse.

\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{c|c|c|c}
			& System 1 & System 2 & System 3 \\ \hline
			\begin{tabular}[c]{@{}c@{}}Laufzeit\\ mean (std) \end{tabular} & 131,4s (77,4s) & 149,8s (95,1s) & 241,5s (154,6s) \\ \hline
			CPU & \begin{tabular}[c]{@{}c@{}}Intel Core i7 - 7700K  \\ 4 x 4,4 GHz \end{tabular} & \begin{tabular}[c]{@{}c@{}}Intel Core i5 - 4590\\ 4 x 3,3 GHz \end{tabular} & \begin{tabular}[c]{@{}c@{}}Intel Core i5\\ 2 x 2,6 GHz \end{tabular} \\ \hline
			RAM & \begin{tabular}[c]{@{}c@{}}16 GB\\ 2133 MHz \\ DDR4 \end{tabular} & \begin{tabular}[c]{@{}c@{}}8 GB\\ 2133 MHz \\ DDR3  \end{tabular} & \begin{tabular}[c]{@{}c@{}}8 GB\\ 1600 MHz \\ DDR3  \end{tabular} \\ \hline
			OS & \begin{tabular}[c]{@{}c@{}}Windows 10 \\ 1803 17134 \end{tabular} & \begin{tabular}[c]{@{}c@{}}Windows 10 \\ 1803 17134  \end{tabular} & \begin{tabular}[c]{@{}c@{}}macOS High Sierra \\ Version 10.13.6  \end{tabular}
		\end{tabular}
		\caption{Evaluierung der Ausführungszeiten auf drei verschiedenen Systemen}
	\end{center}
	\label{tab:evaluierung_laufzeiten}
\end{table}

Eine eigene Evaluierung der Laufzeit kann mit Hilfe des Skriptes $benchmark.m$ im Ordner \textit{/src} des Projektes durchgeführt werden. Die Ergebnisse des Benchmarks werden automatisch im Ordner \textit{/out} gespeichert.
